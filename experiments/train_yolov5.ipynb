{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8291dd6-e5dc-4572-b3d7-cf28df1c9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5\n",
    "# %cd yolov5\n",
    "# %pip install -r requirements.txt\n",
    "# %cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51895619-a204-45d5-ab60-07f5568c3e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘yolo’: File exists\n",
      "mkdir: cannot create directory ‘yolo/train’: File exists\n"
     ]
    }
   ],
   "source": [
    "# !mkdir yolo\n",
    "# !mkdir yolo/train\n",
    "# !mkdir yolo/test\n",
    "\n",
    "# !mkdir ./train_given_dset\n",
    "# !mkdir ./test_given_dset\n",
    "\n",
    "# !mkdir ./train_given_dset/tiger\n",
    "# !mkdir ./train_given_dset/leopard\n",
    "# !mkdir ./test_given_dset/tiger\n",
    "# !mkdir ./test_given_dset/leopard\n",
    "\n",
    "# !mkdir ./train_given_dset/tiger/Label\n",
    "# !mkdir ./train_given_dset/leopard/Label\n",
    "# !mkdir ./test_given_dset/tiger/Label\n",
    "# !mkdir ./test_given_dset/leopard/Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82aa214f-5f69-4c82-93d2-2d663571fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from glob import glob\n",
    "# import random\n",
    "\n",
    "# data_dir=\"./Train_3500/3 класса/\"\n",
    "# tiger_imgs=sorted(glob(data_dir+'Тигры/*jpg'))\n",
    "# tiger_labels=sorted(glob(data_dir+'Тигры/labels/*'))\n",
    "# leopard_imgs=sorted(glob(data_dir+'дальневосточный леопард/*jpg'))\n",
    "# leopard_labels=sorted(glob(data_dir+'дальневосточный леопард/labels/*'))\n",
    "\n",
    "# tiger_imgs_labels = list(zip(tiger_imgs, tiger_labels))\n",
    "# leopard_imgs_labels = list(zip(leopard_imgs, leopard_labels))\n",
    "\n",
    "# random.shuffle(tiger_imgs_labels)\n",
    "# random.shuffle(leopard_imgs_labels)\n",
    "\n",
    "# train_tiger_imgs = [case[0] for case in tiger_imgs_labels[:2500]]\n",
    "# train_tiger_labels = [case[1] for case in tiger_imgs_labels[:2500]]\n",
    "# test_tiger_imgs = [case[0] for case in tiger_imgs_labels[2500:]]\n",
    "# test_tiger_labels = [case[1] for case in tiger_imgs_labels[2500:]]\n",
    "\n",
    "# train_leopard_imgs = [case[0] for case in leopard_imgs_labels[:2500]]\n",
    "# train_leopard_labels = [case[1] for case in leopard_imgs_labels[:2500]]\n",
    "# test_leopard_imgs = [case[0] for case in leopard_imgs_labels[2500:]]\n",
    "# test_leopard_labels = [case[1] for case in leopard_imgs_labels[2500:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "795b9409-0037-4cb9-9688-255795219816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# for img_path in train_tiger_imgs:\n",
    "#     shutil.copyfile(img_path, './train_given_dset/tiger/' + img_path.split('/')[-1])\n",
    "# for img_path in test_tiger_imgs:\n",
    "#     shutil.copyfile(img_path, './test_given_dset/tiger/' + img_path.split('/')[-1])\n",
    "# for img_path in train_leopard_imgs:\n",
    "#     shutil.copyfile(img_path, './train_given_dset/leopard/' + img_path.split('/')[-1])\n",
    "# for img_path in test_leopard_imgs:\n",
    "#     shutil.copyfile(img_path, './test_given_dset/leopard/' + img_path.split('/')[-1])\n",
    "    \n",
    "# for img_path in train_tiger_labels:\n",
    "#     shutil.copyfile(img_path, './train_given_dset/tiger/Label/' + img_path.split('/')[-1])\n",
    "# for img_path in test_tiger_labels:\n",
    "#     shutil.copyfile(img_path, './test_given_dset/tiger/Label/' + img_path.split('/')[-1])\n",
    "# for img_path in train_leopard_labels:\n",
    "#     shutil.copyfile(img_path, './train_given_dset/leopard/Label/' + img_path.split('/')[-1])\n",
    "# for img_path in test_leopard_labels:\n",
    "#     shutil.copyfile(img_path, './test_given_dset/leopard/Label/' + img_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87788fc-a3f1-4612-9703-14dbdc0a51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir=\".\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "all_train_subdir=glob.glob(train_dir+\"/*\")\n",
    "all_test_subdir=glob.glob(test_dir+\"/*\")\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train_given_dset\")\n",
    "test_dir = os.path.join(data_dir, \"test_given_dset\")\n",
    "\n",
    "all_train_given_subdir=glob.glob(train_dir+\"/*\")\n",
    "all_test_given_subdir=glob.glob(test_dir+\"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "455b3d09-6089-464d-acd2-cae9c2ebfe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 82 classes in train dataset, and 82 classes in test dataset\n"
     ]
    }
   ],
   "source": [
    "train_classes=[os.path.basename(pp) for pp in all_train_subdir] + [os.path.basename(pp) for pp in all_train_given_subdir]\n",
    "test_classes=[os.path.basename(pp) for pp in all_test_subdir] + [os.path.basename(pp) for pp in all_test_given_subdir]\n",
    "\n",
    "print(\"There is %d classes in train dataset, and %d classes in test dataset\"%(len(train_classes), len(test_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b68681f-888b-4d75-bfcf-3e7959c6999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_train_dir = \"yolo/train\"\n",
    "# yolo_test_dir = \"yolo/test\"\n",
    "\n",
    "# given dataset train/test\n",
    "# yolo_train_dir = \"yolo/train_given\"\n",
    "# yolo_test_dir = \"yolo/test_given\"\n",
    "\n",
    "# mixed dataset train/test\n",
    "yolo_train_dir = \"yolo/train_mixed\"\n",
    "yolo_test_dir = \"yolo/test_mixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba05a17-ef6c-4bdf-91db-949f695313c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo/train_mixed/images\n",
      "yolo/train_mixed/labels\n",
      "yolo/test_mixed/images\n",
      "yolo/test_mixed/labels\n"
     ]
    }
   ],
   "source": [
    "for dd in [yolo_train_dir, yolo_test_dir]:\n",
    "    for ss in [\"images\", \"labels\"]:\n",
    "        print(os.path.join(dd, ss))\n",
    "        os.makedirs(os.path.join(dd, ss), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0da5eefc-9226-4a8f-be3d-839b5d775306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:56<00:00, 88.00s/it]\n"
     ]
    }
   ],
   "source": [
    "def process_dataset(subdirs, dst_dir, class_names, size=(640,640), link=False):\n",
    "    for subdir_id in tqdm(range(len(subdirs))):\n",
    "        subdir = subdirs[subdir_id]\n",
    "        prefix=os.path.basename(subdir)\n",
    "        for image_file in glob.glob(os.path.join(subdir, \"*.jpg\")):\n",
    "            image_file_basename=os.path.basename(image_file)\n",
    "            label_file = os.path.join(subdir, \"Label\", image_file_basename).replace(\".jpg\", \".txt\")\n",
    "            dst_image_file = os.path.join(dst_dir, \"images/%s_%s\"%(prefix,image_file_basename))\n",
    "            dst_label_file = os.path.join(dst_dir, \"labels/%s_%s\"%(prefix,image_file_basename.replace(\".jpg\", \".txt\")))\n",
    "            if os.path.exists(dst_label_file):\n",
    "                continue\n",
    "            if not os.path.exists(label_file):\n",
    "                continue\n",
    "                        \n",
    "            image = cv2.imread(image_file)                \n",
    "            height, width = image.shape[0:2]\n",
    "            with open(label_file) as fobj:\n",
    "                with open(dst_label_file, \"w\") as wobj:\n",
    "                    while True:\n",
    "                        item = fobj.readline()\n",
    "                        if item is None or len(item)==0:\n",
    "                            break\n",
    "                        class_name = prefix\n",
    "                        item=item[len(class_name):]\n",
    "                        item = item.split()\n",
    "                        xmin = float(item[0])\n",
    "                        ymin = float(item[1])\n",
    "                        xmax = float(item[2])\n",
    "                        ymax = float(item[3])\n",
    "\n",
    "                        cx   = (xmin + xmax)/2.0/width\n",
    "                        cy   = (ymin + ymax)/2.0/height\n",
    "                        bw   = (xmax - xmin)/width\n",
    "                        bh   = (ymax - ymin)/height\n",
    "                        class_id = class_names.index(class_name)\n",
    "                        output_line = \"%d %f %f %f %f\\n\"%(class_id, cx, cy, bw, bh)\n",
    "                        wobj.write(output_line)\n",
    "\n",
    "            if link==True:\n",
    "                os.symlink(image_file, dst_image_file)\n",
    "            else:\n",
    "                image = cv2.resize(image, size)\n",
    "                cv2.imwrite(dst_image_file, image)\n",
    "                \n",
    "classes = ['bear', 'deer', 'fox', 'rabbit', 'lion', 'leopard', 'cheetah', 'tiger']\n",
    "# process_dataset(all_train_subdir, yolo_train_dir, train_classes, size=(640,640), link=False) \n",
    "\n",
    "xueqin_train_subdir = [pp for pp in all_train_subdir if os.path.basename(pp).lower() in classes] + all_train_given_subdir\n",
    "xueqin_classes=[os.path.basename(pp) for pp in xueqin_train_subdir]\n",
    "\n",
    "process_dataset(xueqin_train_subdir, yolo_train_dir, xueqin_classes, size=(640,640), link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20d6b032-8241-47c7-9e88-914e432d586c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:56<00:00, 88.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# xueqin_test_subdir = [pp for pp in all_test_subdir if os.path.basename(pp).lower() in classes]\n",
    "xueqin_test_subdir = all_train_subdir\n",
    "process_dataset(xueqin_test_subdir, yolo_test_dir, xueqin_classes, size=(640,640), link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49b75a01-c505-4f05-8a0a-f61325b88bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file=\"yolov5/data/animal_given.yaml\"\n",
    "train_images_dir = os.path.join(\"..\", yolo_train_dir, \"images\")\n",
    "val_images_dir = os.path.join(\"..\", yolo_test_dir, \"images\")\n",
    "\n",
    "names_str=\"\"\n",
    "for item in xueqin_classes:\n",
    "    names_str=names_str + \", \\'%s\\'\"%item\n",
    "names_str= \"names: [\"+names_str[1:]+\"]\"\n",
    "\n",
    "with open(yaml_file, \"w\") as wobj:\n",
    "    wobj.write(\"train: %s\\n\"%train_images_dir)\n",
    "    wobj.write(\"val: %s\\n\"%val_images_dir)\n",
    "    wobj.write(\"nc: %d\\n\"%len(xueqin_classes))\n",
    "    wobj.write(names_str+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58b6c879-faed-4a61-bcf1-bc62964f031e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msjeffry\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6b5bcb3-6d11-4c51-a264-54b81508c380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/samara_hack_solution/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f581c0-1621-443a-bd7a-9d840b8a6446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msjeffry\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=data/animal_given.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=60, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0,1, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=animals_given_xl, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v6.0-109-g7c6bae0 torch 1.10.0+cu102 CUDA:0 (Tesla V100S-PCIE-32GB, 32510MiB)\n",
      "                                               CUDA:1 (Tesla V100S-PCIE-32GB, 32510MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33manimals_given_xl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/sjeffry/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/sjeffry/YOLOv5/runs/vzp8d3xi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/samara_hack_solution/yolov5/wandb/run-20211126_225059-vzp8d3xi\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
      "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
      "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
      " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
      " 24      [17, 20, 23]  1     47103  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
      "Model Summary: 567 layers, 86224543 parameters, 86224543 gradients, 204.2 GFLOPs\n",
      "\n",
      "Transferred 739/745 items from yolov5x.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 123 weight, 126 weight (no decay), 126 bias\n",
      "WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../yolo/train_given/labels.cache' images and labels... 3986 fou\u001b[0m\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../yolo/train_given/images/leopard_125_IMAG0217_S02.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0109]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../yolo/train_given/images/leopard_212_IMG_0247_S02.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../yolo/train_given/images/tiger_001_1974.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../yolo/train_given/images/tiger_001_2428.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../yolo/train_given/images/tiger_001_341.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0002]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../yolo/train_given/images/tiger_002_102.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0101]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../yolo/train_given/images/tiger_002_177.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../yolo/train_given/images/tiger_002_181.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0059]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../yolo/train_given/images/tiger_002_377.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0022]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../yolo/train_given/labels.cache' images and labels... 3986 fou\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../yolo/test_given/labels.cache' images and labels... 3986 found,\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../yolo/test_given/images/leopard_125_IMAG0217_S02.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0109]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../yolo/test_given/images/leopard_212_IMG_0247_S02.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.002]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../yolo/test_given/images/tiger_001_1974.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../yolo/test_given/images/tiger_001_2428.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0004]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../yolo/test_given/images/tiger_001_341.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0002]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../yolo/test_given/images/tiger_002_102.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0101]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../yolo/test_given/images/tiger_002_177.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.001]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../yolo/test_given/images/tiger_002_181.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0059]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../yolo/test_given/images/tiger_002_377.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0022]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../yolo/test_given/labels.cache' images and labels... 3986 found,\u001b[0m\n",
      "Plotting labels to runs/train/animals_given_xl6/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.29 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/animals_given_xl6\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/59     24.9G    0.1109   0.02675   0.02959       146       640:  10%|▉  "
     ]
    }
   ],
   "source": [
    "!python train.py --data data/animal_given.yaml --batch-size 64 --epochs 60 --img-size 640 --project runs/train --name animals_given_xl --weights yolov5x.pt --device 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4ae9451-4d2f-4045-9d94-e58ce7ed0ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/samara_hack_solution/yolov5/runs/train/animals_given_medium/weights/best.pt'], source=/home/samara_hack_solution/test_given_dset/leopard/01180092_S02.jpg, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=animals_given, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v6.0-109-g7c6bae0 torch 1.10.0+cu102 CUDA:0 (Tesla V100S-PCIE-32GB, 32510MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 290 layers, 20856975 parameters, 0 gradients, 48.0 GFLOPs\n",
      "image 1/1 /home/samara_hack_solution/test_given_dset/leopard/01180092_S02.jpg: 480x640 1 leopard, Done. (0.008s)\n",
      "Speed: 0.5ms pre-process, 8.4ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/animals_given3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights /home/samara_hack_solution/yolov5/runs/train/animals_given_medium/weights/best.pt --source /home/samara_hack_solution/test_given_dset/leopard/01180092_S02.jpg --name animals_given --project runs/detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134c878-60ed-46e4-a206-04516b5a9fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
